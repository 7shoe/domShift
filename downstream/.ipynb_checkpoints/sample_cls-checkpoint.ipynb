{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280500b5-5cd2-4ac7-b777-bb2155798346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d988b71-351d-4403-bd6a-7fda7ecbfe90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC Accuracy: 0.9246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1185\n",
      "           1       0.97      0.98      0.98      1348\n",
      "           2       0.91      0.92      0.92      1192\n",
      "           3       0.89      0.89      0.89      1226\n",
      "           4       0.93      0.91      0.92      1168\n",
      "           5       0.92      0.89      0.90      1084\n",
      "           6       0.95      0.96      0.95      1184\n",
      "           7       0.95      0.92      0.94      1253\n",
      "           8       0.88      0.90      0.89      1170\n",
      "           9       0.89      0.90      0.89      1190\n",
      "\n",
      "    accuracy                           0.92     12000\n",
      "   macro avg       0.92      0.92      0.92     12000\n",
      "weighted avg       0.92      0.92      0.92     12000\n",
      "\n",
      "\n",
      "RandomForest Accuracy: 0.8301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88      1185\n",
      "           1       0.96      0.96      0.96      1348\n",
      "           2       0.84      0.80      0.82      1192\n",
      "           3       0.76      0.78      0.77      1226\n",
      "           4       0.77      0.83      0.80      1168\n",
      "           5       0.87      0.67      0.76      1084\n",
      "           6       0.86      0.92      0.89      1184\n",
      "           7       0.85      0.82      0.84      1253\n",
      "           8       0.76      0.81      0.78      1170\n",
      "           9       0.76      0.78      0.77      1190\n",
      "\n",
      "    accuracy                           0.83     12000\n",
      "   macro avg       0.83      0.83      0.83     12000\n",
      "weighted avg       0.83      0.83      0.83     12000\n",
      "\n",
      "\n",
      "MLP Accuracy: 0.9323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      1185\n",
      "           1       0.98      0.98      0.98      1348\n",
      "           2       0.92      0.92      0.92      1192\n",
      "           3       0.90      0.90      0.90      1226\n",
      "           4       0.93      0.93      0.93      1168\n",
      "           5       0.92      0.90      0.91      1084\n",
      "           6       0.95      0.96      0.96      1184\n",
      "           7       0.95      0.96      0.95      1253\n",
      "           8       0.91      0.89      0.90      1170\n",
      "           9       0.90      0.92      0.91      1190\n",
      "\n",
      "    accuracy                           0.93     12000\n",
      "   macro avg       0.93      0.93      0.93     12000\n",
      "weighted avg       0.93      0.93      0.93     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PATHS\n",
    "BASE = \"/eagle/projects/argonne_tpc/siebenschuh/domain_shift_data\"\n",
    "EMB_PATH = os.path.join(BASE, \"embeddings\", \"SimSiam_moderate_best_embeddings.npy\")\n",
    "LBL_PATH = os.path.join(BASE, \"embeddings\", \"SimSiam_moderate_best_labels.npy\")\n",
    "DATASETS = [\"uniform\", \"moderate\", \"heavy\"]\n",
    "\n",
    "# ─── 1) Load embeddings + labels for the SSL subset ────────────────────────────\n",
    "X_all = np.load(EMB_PATH)\n",
    "y_all = np.load(LBL_PATH).ravel()\n",
    "\n",
    "yaml_path = os.path.join(BASE, \"datasets\", f\"MNIST_moderate.yaml\")\n",
    "with open(yaml_path) as f:\n",
    "    moderate_cfg = yaml.safe_load(f)\n",
    "\n",
    "train_idx = np.array(moderate_cfg[\"not_subsampled_indices\"], dtype=int)\n",
    "X_train, y_train = X_all[train_idx], y_all[train_idx]\n",
    "\n",
    "# ─── 2) Build EXCLUDED index‑set (union of all three splits) ───────────────────\n",
    "excluded = set()\n",
    "for ds in DATASETS:\n",
    "    cfg_path = os.path.join(BASE, \"datasets\", f\"MNIST_{ds}.yaml\")\n",
    "    with open(cfg_path) as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "    excluded.update(cfg[\"not_subsampled_indices\"])\n",
    "excluded = np.array(sorted(excluded), dtype=int)\n",
    "\n",
    "# ─── 3) Fetch FULL MNIST (raw) ────────────────────────────────────────────────\n",
    "mnist = fetch_openml(\"mnist_784\", version=1, as_frame=False)\n",
    "X_full, y_full = mnist[\"data\"], mnist[\"target\"].astype(int)\n",
    "\n",
    "# ─── 4) Select a balanced 10k test‑set outside ALL subsets ────────────────────\n",
    "mask = np.ones(len(y_full), dtype=bool)\n",
    "mask[excluded] = False\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "test_indices = []\n",
    "for cls in range(10):\n",
    "    candidates = np.where((mask) & (y_full == cls))[0]\n",
    "    chosen = rng.choice(candidates, size=1000, replace=False)\n",
    "    test_indices.append(chosen)\n",
    "test_indices = np.concatenate(test_indices)\n",
    "\n",
    "y_test = y_full[test_indices]\n",
    "\n",
    "# ─── 5) LOAD or COMPUTE EMBEDDINGS for TEST set ────────────────────────────────\n",
    "# If you’ve precomputed embeddings for full MNIST, load them here:\n",
    "# full_emb = np.load(\"/path/to/SimSiam_full_embeddings.npy\")\n",
    "# X_test = full_emb[test_indices]\n",
    "\n",
    "# Otherwise compute via your SSL encoder:\n",
    "# def encode(images): ...\n",
    "# X_test = encode(X_full[test_indices])\n",
    "\n",
    "raise NotImplementedError(\n",
    "    \"Fill in either loading or computing embeddings for the held-out test set\"\n",
    ")\n",
    "\n",
    "# ─── 6) STANDARDIZE & TRAIN/EVALUATE ─────────────────────────────────────────\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "classifiers = {\n",
    "    \"SVC\": SVC(kernel=\"rbf\", probability=True, random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,100), max_iter=500, random_state=42),\n",
    "}\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    print(f\"\\n{name} Accuracy: {accuracy_score(y_test, preds):.4f}\")\n",
    "    print(classification_report(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7a437de-2b40-43c3-90a3-cf35c8ffc85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24a2d046-b2d8-4d77-ab70-cd5f2a10d406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC Accuracy: 0.9096\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      1185\n",
      "           1       0.96      0.97      0.97      1348\n",
      "           2       0.91      0.92      0.92      1192\n",
      "           3       0.88      0.89      0.89      1226\n",
      "           4       0.93      0.91      0.92      1168\n",
      "           5       0.88      0.85      0.86      1084\n",
      "           6       0.96      0.94      0.95      1184\n",
      "           7       0.93      0.89      0.91      1253\n",
      "           8       0.86      0.87      0.86      1170\n",
      "           9       0.82      0.89      0.85      1190\n",
      "\n",
      "    accuracy                           0.91     12000\n",
      "   macro avg       0.91      0.91      0.91     12000\n",
      "weighted avg       0.91      0.91      0.91     12000\n",
      "\n",
      "\n",
      "RandomForest Accuracy: 0.8393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      1185\n",
      "           1       0.95      0.96      0.95      1348\n",
      "           2       0.83      0.86      0.85      1192\n",
      "           3       0.78      0.82      0.80      1226\n",
      "           4       0.87      0.84      0.86      1168\n",
      "           5       0.80      0.70      0.75      1084\n",
      "           6       0.90      0.90      0.90      1184\n",
      "           7       0.87      0.81      0.84      1253\n",
      "           8       0.73      0.76      0.74      1170\n",
      "           9       0.78      0.82      0.80      1190\n",
      "\n",
      "    accuracy                           0.84     12000\n",
      "   macro avg       0.84      0.84      0.84     12000\n",
      "weighted avg       0.84      0.84      0.84     12000\n",
      "\n",
      "\n",
      "MLP Accuracy: 0.9425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1185\n",
      "           1       0.97      0.98      0.97      1348\n",
      "           2       0.95      0.94      0.94      1192\n",
      "           3       0.93      0.91      0.92      1226\n",
      "           4       0.96      0.94      0.95      1168\n",
      "           5       0.88      0.94      0.91      1084\n",
      "           6       0.97      0.96      0.97      1184\n",
      "           7       0.96      0.93      0.95      1253\n",
      "           8       0.92      0.91      0.91      1170\n",
      "           9       0.91      0.93      0.92      1190\n",
      "\n",
      "    accuracy                           0.94     12000\n",
      "   macro avg       0.94      0.94      0.94     12000\n",
      "weighted avg       0.94      0.94      0.94     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Load data\n",
    "X = np.load('/eagle/projects/argonne_tpc/siebenschuh/domain_shift_data/embeddings/SimSiam_moderate_worst_embeddings.npy')\n",
    "y = np.load('/eagle/projects/argonne_tpc/siebenschuh/domain_shift_data/embeddings/SimSiam_moderate_worst_labels.npy')\n",
    "\n",
    "# If labels are shape (n,1), flatten to (n,)\n",
    "y = y.ravel()\n",
    "\n",
    "# 2) Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 3) Standardize features (important for SVC + MLP)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "# 4) Define classifiers\n",
    "classifiers = {\n",
    "    \"SVC\": SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,100), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "# 5) Train + evaluate\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    print(f\"\\n{name} Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0752e5ca-a99d-4384-8e0a-4be59ded2d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC Accuracy: 0.9574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1185\n",
      "           1       0.99      0.99      0.99      1348\n",
      "           2       0.94      0.94      0.94      1192\n",
      "           3       0.91      0.93      0.92      1226\n",
      "           4       0.98      0.99      0.99      1168\n",
      "           5       0.96      0.90      0.93      1084\n",
      "           6       0.96      0.96      0.96      1184\n",
      "           7       0.97      0.96      0.96      1253\n",
      "           8       0.93      0.95      0.94      1170\n",
      "           9       0.95      0.94      0.95      1190\n",
      "\n",
      "    accuracy                           0.96     12000\n",
      "   macro avg       0.96      0.96      0.96     12000\n",
      "weighted avg       0.96      0.96      0.96     12000\n",
      "\n",
      "\n",
      "RandomForest Accuracy: 0.9114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      1185\n",
      "           1       0.99      0.99      0.99      1348\n",
      "           2       0.90      0.89      0.89      1192\n",
      "           3       0.78      0.83      0.81      1226\n",
      "           4       0.97      0.98      0.97      1168\n",
      "           5       0.86      0.75      0.80      1084\n",
      "           6       0.94      0.94      0.94      1184\n",
      "           7       0.94      0.94      0.94      1253\n",
      "           8       0.85      0.89      0.87      1170\n",
      "           9       0.91      0.91      0.91      1190\n",
      "\n",
      "    accuracy                           0.91     12000\n",
      "   macro avg       0.91      0.91      0.91     12000\n",
      "weighted avg       0.91      0.91      0.91     12000\n",
      "\n",
      "\n",
      "MLP Accuracy: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1185\n",
      "           1       0.99      0.99      0.99      1348\n",
      "           2       0.97      0.98      0.97      1192\n",
      "           3       0.95      0.96      0.96      1226\n",
      "           4       0.99      0.98      0.99      1168\n",
      "           5       0.99      0.93      0.96      1084\n",
      "           6       0.98      0.99      0.98      1184\n",
      "           7       0.99      0.97      0.98      1253\n",
      "           8       0.95      0.98      0.96      1170\n",
      "           9       0.96      0.98      0.97      1190\n",
      "\n",
      "    accuracy                           0.98     12000\n",
      "   macro avg       0.98      0.98      0.98     12000\n",
      "weighted avg       0.98      0.98      0.98     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Load data\n",
    "X = np.load('/eagle/projects/argonne_tpc/siebenschuh/domain_shift_data/embeddings/SimCLR_heavy_best_embeddings.npy')\n",
    "y = np.load('/eagle/projects/argonne_tpc/siebenschuh/domain_shift_data/embeddings/SimCLR_heavy_best_labels.npy')\n",
    "\n",
    "# If labels are shape (n,1), flatten to (n,)\n",
    "y = y.ravel()\n",
    "\n",
    "# 2) Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 3) Standardize features (important for SVC + MLP)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "# 4) Define classifiers\n",
    "classifiers = {\n",
    "    \"SVC\": SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,100), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "# 5) Train + evaluate\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    print(f\"\\n{name} Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "275a04f5-d9d6-4e0c-b0d1-653168777251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC Accuracy: 0.9597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1185\n",
      "           1       0.98      0.98      0.98      1348\n",
      "           2       0.96      0.96      0.96      1192\n",
      "           3       0.95      0.94      0.94      1226\n",
      "           4       0.96      0.95      0.95      1168\n",
      "           5       0.96      0.94      0.95      1084\n",
      "           6       0.97      0.98      0.97      1184\n",
      "           7       0.97      0.97      0.97      1253\n",
      "           8       0.91      0.95      0.93      1170\n",
      "           9       0.95      0.94      0.94      1190\n",
      "\n",
      "    accuracy                           0.96     12000\n",
      "   macro avg       0.96      0.96      0.96     12000\n",
      "weighted avg       0.96      0.96      0.96     12000\n",
      "\n",
      "\n",
      "RandomForest Accuracy: 0.8909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1185\n",
      "           1       0.96      0.97      0.97      1348\n",
      "           2       0.90      0.89      0.90      1192\n",
      "           3       0.87      0.87      0.87      1226\n",
      "           4       0.86      0.90      0.88      1168\n",
      "           5       0.91      0.81      0.85      1084\n",
      "           6       0.92      0.95      0.93      1184\n",
      "           7       0.92      0.85      0.89      1253\n",
      "           8       0.81      0.85      0.83      1170\n",
      "           9       0.85      0.87      0.86      1190\n",
      "\n",
      "    accuracy                           0.89     12000\n",
      "   macro avg       0.89      0.89      0.89     12000\n",
      "weighted avg       0.89      0.89      0.89     12000\n",
      "\n",
      "\n",
      "MLP Accuracy: 0.9567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      1185\n",
      "           1       0.98      0.98      0.98      1348\n",
      "           2       0.96      0.95      0.96      1192\n",
      "           3       0.95      0.95      0.95      1226\n",
      "           4       0.96      0.95      0.95      1168\n",
      "           5       0.95      0.94      0.95      1084\n",
      "           6       0.97      0.98      0.98      1184\n",
      "           7       0.97      0.95      0.96      1253\n",
      "           8       0.92      0.93      0.93      1170\n",
      "           9       0.93      0.94      0.93      1190\n",
      "\n",
      "    accuracy                           0.96     12000\n",
      "   macro avg       0.96      0.96      0.96     12000\n",
      "weighted avg       0.96      0.96      0.96     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Load data\n",
    "X = np.load('/eagle/projects/argonne_tpc/siebenschuh/domain_shift_data/embeddings/BYOL_heavy_best_embeddings.npy')\n",
    "y = np.load('/eagle/projects/argonne_tpc/siebenschuh/domain_shift_data/embeddings/BYOL_heavy_best_labels.npy')\n",
    "\n",
    "# If labels are shape (n,1), flatten to (n,)\n",
    "y = y.ravel()\n",
    "\n",
    "# 2) Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 3) Standardize features (important for SVC + MLP)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "# 4) Define classifiers\n",
    "classifiers = {\n",
    "    \"SVC\": SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,100), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "# 5) Train + evaluate\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    print(f\"\\n{name} Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d3cd9e-88b3-459f-940c-deb070bbe8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC Accuracy: 0.9685\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      1185\n",
      "           1       0.99      0.99      0.99      1348\n",
      "           2       0.96      0.97      0.96      1192\n",
      "           3       0.96      0.96      0.96      1226\n",
      "           4       0.98      0.96      0.97      1168\n",
      "           5       0.97      0.96      0.96      1084\n",
      "           6       0.98      0.98      0.98      1184\n",
      "           7       0.97      0.96      0.97      1253\n",
      "           8       0.95      0.96      0.95      1170\n",
      "           9       0.94      0.96      0.95      1190\n",
      "\n",
      "    accuracy                           0.97     12000\n",
      "   macro avg       0.97      0.97      0.97     12000\n",
      "weighted avg       0.97      0.97      0.97     12000\n",
      "\n",
      "\n",
      "RandomForest Accuracy: 0.9068\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      1185\n",
      "           1       0.96      0.97      0.97      1348\n",
      "           2       0.90      0.91      0.90      1192\n",
      "           3       0.89      0.88      0.89      1226\n",
      "           4       0.91      0.89      0.90      1168\n",
      "           5       0.92      0.85      0.89      1084\n",
      "           6       0.94      0.94      0.94      1184\n",
      "           7       0.92      0.88      0.90      1253\n",
      "           8       0.85      0.88      0.86      1170\n",
      "           9       0.84      0.90      0.87      1190\n",
      "\n",
      "    accuracy                           0.91     12000\n",
      "   macro avg       0.91      0.91      0.91     12000\n",
      "weighted avg       0.91      0.91      0.91     12000\n",
      "\n",
      "\n",
      "MLP Accuracy: 0.9637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1185\n",
      "           1       0.99      0.97      0.98      1348\n",
      "           2       0.94      0.97      0.96      1192\n",
      "           3       0.96      0.95      0.95      1226\n",
      "           4       0.96      0.96      0.96      1168\n",
      "           5       0.97      0.95      0.96      1084\n",
      "           6       0.98      0.98      0.98      1184\n",
      "           7       0.97      0.97      0.97      1253\n",
      "           8       0.93      0.94      0.94      1170\n",
      "           9       0.95      0.95      0.95      1190\n",
      "\n",
      "    accuracy                           0.96     12000\n",
      "   macro avg       0.96      0.96      0.96     12000\n",
      "weighted avg       0.96      0.96      0.96     12000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = np.load('/eagle/projects/argonne_tpc/siebenschuh/domain_shift_data/embeddings/BYOL_uniform_best_embeddings.npy')\n",
    "y = np.load('/eagle/projects/argonne_tpc/siebenschuh/domain_shift_data/embeddings/BYOL_uniform_best_labels.npy')\n",
    "\n",
    "# If labels are shape (n,1), flatten to (n,)\n",
    "y = y.ravel()\n",
    "\n",
    "# 2) Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 3) Standardize features (important for SVC + MLP)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "# 4) Define classifiers\n",
    "classifiers = {\n",
    "    \"SVC\": SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100,100), max_iter=500, random_state=42)\n",
    "}\n",
    "\n",
    "# 5) Train + evaluate\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    print(f\"\\n{name} Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f11bef-a7b2-4756-9d84-7058e8e136f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bo",
   "language": "python",
   "name": "bo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
