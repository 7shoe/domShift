{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "454b52e3-b357-4b13-9a6e-810ebf1cbd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from pathlib import Path\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695a9fc4-b203-42e5-ad28-bba842e2d1a1",
   "metadata": {},
   "source": [
    "# 1. Download Sweep data from W&B API\n",
    "Do so only if new sweeps where run under project name `domShift`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0222bd-f25f-44f0-bb71-73271055d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_again = False\n",
    "\n",
    "if download_again:\n",
    "    # setup\n",
    "    api = wandb.Api()\n",
    "    \n",
    "    # Project is specified by <entity/project-name>\n",
    "    runs = api.runs(\"7shoe/domShift-src\")\n",
    "    \n",
    "    summary_list, config_list, name_list = [], [], []\n",
    "    for run in runs: \n",
    "        # .summary contains the output keys/values for metrics like accuracy.\n",
    "        #  We call ._json_dict to omit large files \n",
    "        summary_list.append(run.summary._json_dict)\n",
    "    \n",
    "        # .config contains the hyperparameters.\n",
    "        #  We remove special values that start with _.\n",
    "        config_list.append(\n",
    "            {k: v for k,v in run.config.items()\n",
    "              if not k.startswith('_')})\n",
    "    \n",
    "        # .name is the human-readable name of the run.\n",
    "        name_list.append(run.name)\n",
    "    \n",
    "    runs_df = pd.DataFrame({\n",
    "        \"summary\": summary_list,\n",
    "        \"config\": config_list,\n",
    "        \"name\": name_list\n",
    "        })\n",
    "    \n",
    "    runs_df.to_csv(\"./report/sweep3.csv\") # new name should be `sweep3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a29a797-485c-40d4-8b6b-c2972072e48b",
   "metadata": {},
   "source": [
    "# 2. Process downloaded W&B frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df90bd40-7c00-4470-9138-7a77f24283d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "currate_best_models_again = True\n",
    "\n",
    "if currate_best_models_again:\n",
    "    # current sweep = 2\n",
    "    df = pd.read_csv('./report/sweep2.csv')\n",
    "    \n",
    "    # Convert the 'summary' and 'config' columns from strings to dictionaries.\n",
    "    df['summary'] = df['summary'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else {})\n",
    "    df['config'] = df['config'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else {})\n",
    "    \n",
    "    # Now expand the dictionary columns.\n",
    "    summary_expanded = pd.json_normalize(df['summary'])\n",
    "    config_expanded = pd.json_normalize(df['config'])\n",
    "    \n",
    "    # Join them back into the original dataframe.\n",
    "    df = df.drop(columns=['summary', 'config']).join(summary_expanded).join(config_expanded)\n",
    "    \n",
    "    # subset to sweep 2 (all 15 epochs)\n",
    "    df=df[df['epoch']==15]\n",
    "    \n",
    "    # best frame\n",
    "    best_rows = []\n",
    "    for model in ['SimCLR', 'SimSiam', 'BYOL']:\n",
    "        for dataset in ['uniform', 'moderate', 'heavy']:\n",
    "            sub_df = df[(df['model'] == model) & (df['dataset'] == dataset)]\n",
    "            if not sub_df.empty:\n",
    "                best_row = sub_df.loc[sub_df['val_loss'].idxmin()]\n",
    "                best_rows.append(best_row[['dataset', 'model', 'checkpoint', 'train_loss', 'val_loss', 'epoch', 'batch_size', 'temperature', 'learning_rate']])\n",
    "            else:\n",
    "                print(f\"No data for model={model} and dataset={dataset}\")\n",
    "    \n",
    "    # Combine the results into a single DataFrame.\n",
    "    best_df = pd.DataFrame(best_rows)\n",
    "    \n",
    "    # delta\n",
    "    best_df['gen_gap'] = best_df['val_loss'] - best_df['train_loss']\n",
    "    \n",
    "    # store\n",
    "    best_df.to_csv('./report/best_models.csv', index=None)\n",
    "    best_df.sort_values(by=\"dataset\", inplace=True)\n",
    "else:\n",
    "    best_df = pd.read_csv('./report/best_models.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bo",
   "language": "python",
   "name": "bo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
